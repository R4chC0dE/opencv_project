{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RIAIuc3myCOI"
   },
   "source": [
    "<h1 style=\"font-size:30px;\">Application: Lane Detection in video</h1> \n",
    "\n",
    "This notebook will help you to detect lanes in a video using OpenCV. In the previous notebook, you learned how to detect lanes in a single image. In this notebook, you will see how to apply this pipeline to a video example, as well as consider of some of the limitations and possible extensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oZ7wcKMQyCOK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    print(\"Downloading Code to Colab Environment\")\n",
    "    !wget https://www.dropbox.com/sh/93k0ei59i6p554o/AAD1WAU_u25zZCs5LqyBDhaZa?dl=1 -O module-code.zip -q --show-progress\n",
    "    !unzip -qq module-code.zip\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "SLRrQUqdyCOJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video __temp__.mp4.\n",
      "MoviePy - Writing audio in __temp__TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video __temp__.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "must be real number, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m clip \u001b[38;5;241m=\u001b[39m VideoFileClip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlane1-straight.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m clip\u001b[38;5;241m.\u001b[39mset_fps(\u001b[38;5;241m30\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mclip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mipython_display\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\condaenv\\lib\\site-packages\\moviepy\\video\\io\\html_tools.py:220\u001b[0m, in \u001b[0;36mipython_display\u001b[1;34m(clip, filetype, maxduration, t, fps, rd_kwargs, center, **html_kwargs)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    218\u001b[0m     clip \u001b[38;5;241m=\u001b[39m clip\u001b[38;5;241m.\u001b[39mto_ImageClip(t)\n\u001b[1;32m--> 220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m HTML2(html_embed(clip, filetype\u001b[38;5;241m=\u001b[39mfiletype, maxduration\u001b[38;5;241m=\u001b[39mmaxduration,\n\u001b[0;32m    221\u001b[0m             center\u001b[38;5;241m=\u001b[39mcenter, rd_kwargs\u001b[38;5;241m=\u001b[39mrd_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhtml_kwargs))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\condaenv\\lib\\site-packages\\moviepy\\video\\io\\html_tools.py:98\u001b[0m, in \u001b[0;36mhtml_embed\u001b[1;34m(clip, filetype, maxduration, rd_kwargs, center, **html_kwargs)\u001b[0m\n\u001b[0;32m     96\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m:filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreset\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124multrafast\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[0;32m     97\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate(rd_kwargs)\n\u001b[1;32m---> 98\u001b[0m     clip\u001b[38;5;241m.\u001b[39mwrite_videofile(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(clip,AudioClip):\n\u001b[0;32m    100\u001b[0m     filename \u001b[38;5;241m=\u001b[39m TEMP_PREFIX\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.mp3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\condaenv\\lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\condaenv\\lib\\site-packages\\moviepy\\decorators.py:54\u001b[0m, in \u001b[0;36mrequires_duration\u001b[1;34m(f, clip, *a, **k)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not set\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(clip, \u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mk)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\condaenv\\lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\condaenv\\lib\\site-packages\\moviepy\\decorators.py:135\u001b[0m, in \u001b[0;36muse_clip_fps_by_default\u001b[1;34m(f, clip, *a, **k)\u001b[0m\n\u001b[0;32m    130\u001b[0m new_a \u001b[38;5;241m=\u001b[39m [fun(arg) \u001b[38;5;28;01mif\u001b[39;00m (name\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfps\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m arg\n\u001b[0;32m    131\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m (arg, name) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(a, names)]\n\u001b[0;32m    132\u001b[0m new_kw \u001b[38;5;241m=\u001b[39m {k: fun(v) \u001b[38;5;28;01mif\u001b[39;00m k\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfps\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m v\n\u001b[0;32m    133\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m (k,v) \u001b[38;5;129;01min\u001b[39;00m k\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m--> 135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(clip, \u001b[38;5;241m*\u001b[39mnew_a, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnew_kw)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\condaenv\\lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\condaenv\\lib\\site-packages\\moviepy\\decorators.py:22\u001b[0m, in \u001b[0;36mconvert_masks_to_RGB\u001b[1;34m(f, clip, *a, **k)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clip\u001b[38;5;241m.\u001b[39mismask:\n\u001b[0;32m     21\u001b[0m     clip \u001b[38;5;241m=\u001b[39m clip\u001b[38;5;241m.\u001b[39mto_RGB()\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(clip, \u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mk)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\condaenv\\lib\\site-packages\\moviepy\\video\\VideoClip.py:300\u001b[0m, in \u001b[0;36mVideoClip.write_videofile\u001b[1;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, logger)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m make_audio:\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio\u001b[38;5;241m.\u001b[39mwrite_audiofile(audiofile, audio_fps,\n\u001b[0;32m    294\u001b[0m                                audio_nbytes, audio_bufsize,\n\u001b[0;32m    295\u001b[0m                                audio_codec, bitrate\u001b[38;5;241m=\u001b[39maudio_bitrate,\n\u001b[0;32m    296\u001b[0m                                write_logfile\u001b[38;5;241m=\u001b[39mwrite_logfile,\n\u001b[0;32m    297\u001b[0m                                verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    298\u001b[0m                                logger\u001b[38;5;241m=\u001b[39mlogger)\n\u001b[1;32m--> 300\u001b[0m \u001b[43mffmpeg_write_video\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcodec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mbitrate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbitrate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mpreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mwrite_logfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_logfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m                   \u001b[49m\u001b[43maudiofile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maudiofile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mffmpeg_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mffmpeg_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remove_temp \u001b[38;5;129;01mand\u001b[39;00m make_audio:\n\u001b[0;32m    310\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(audiofile):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\condaenv\\lib\\site-packages\\moviepy\\video\\io\\ffmpeg_writer.py:213\u001b[0m, in \u001b[0;36mffmpeg_write_video\u001b[1;34m(clip, filename, fps, codec, bitrate, preset, withmask, write_logfile, audiofile, verbose, threads, ffmpeg_params, logger)\u001b[0m\n\u001b[0;32m    211\u001b[0m     logfile \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    212\u001b[0m logger(message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMoviepy - Writing video \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m filename)\n\u001b[1;32m--> 213\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mFFMPEG_VideoWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcodec\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcodec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mpreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbitrate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbitrate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m                            \u001b[49m\u001b[43maudiofile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maudiofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mffmpeg_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mffmpeg_params\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m writer:\n\u001b[0;32m    218\u001b[0m     nframes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(clip\u001b[38;5;241m.\u001b[39mduration\u001b[38;5;241m*\u001b[39mfps)\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t,frame \u001b[38;5;129;01min\u001b[39;00m clip\u001b[38;5;241m.\u001b[39miter_frames(logger\u001b[38;5;241m=\u001b[39mlogger, with_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    221\u001b[0m                                     fps\u001b[38;5;241m=\u001b[39mfps, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\condaenv\\lib\\site-packages\\moviepy\\video\\io\\ffmpeg_writer.py:88\u001b[0m, in \u001b[0;36mFFMPEG_VideoWriter.__init__\u001b[1;34m(self, filename, size, fps, codec, audiofile, preset, bitrate, withmask, logfile, threads, ffmpeg_params)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mext \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# order is important\u001b[39;00m\n\u001b[0;32m     80\u001b[0m cmd \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     81\u001b[0m     get_setting(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFFMPEG_BINARY\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-y\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-loglevel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m logfile \u001b[38;5;241m==\u001b[39m sp\u001b[38;5;241m.\u001b[39mPIPE \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minfo\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-f\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrawvideo\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-vcodec\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrawvideo\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-s\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124mx\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (size[\u001b[38;5;241m0\u001b[39m], size[\u001b[38;5;241m1\u001b[39m]),\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-pix_fmt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrgba\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m withmask \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrgb24\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-r\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m%.02f\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m,\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-an\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-i\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     90\u001b[0m ]\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m audiofile \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     cmd\u001b[38;5;241m.\u001b[39mextend([\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-i\u001b[39m\u001b[38;5;124m'\u001b[39m, audiofile,\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-acodec\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcopy\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     95\u001b[0m     ])\n",
      "\u001b[1;31mTypeError\u001b[0m: must be real number, not NoneType"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import *\n",
    "# from moviepy.video.io.html_tools import ipython_display\n",
    "clip = VideoFileClip('lane1-straight.mp4')\n",
    "clip.set_fps(30)\n",
    "clip.ipython_display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LMntZ4IoyCOK"
   },
   "source": [
    "# 1. Define Utility Functions From Straight Lane Image\n",
    "\n",
    "Below are several utility functions that we will use to run our pipeline.\n",
    "\n",
    "### <font style='color:rgb(50,120,230)'> 1.1 Function from code ocvered in straight lane in image detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jUekoER-yCOK"
   },
   "outputs": [],
   "source": [
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"Select the region of interest (ROI) from a defined list of vertices.\"\"\"\n",
    "    # Defines a blank mask.\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    # Defining a 3 channel or 1 channel color to fill the mask.\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # 3 or 4 depending on your image.\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    # Filling pixels inside the polygon.\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    # Returning the image only where mask pixels are nonzero.\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness = 2):\n",
    "    \"\"\"Utility for drawing lines.\"\"\"\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            for x1,y1,x2,y2 in line:\n",
    "                cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"Utility for defining Line Segments.\"\"\"\n",
    "    lines = cv2.HoughLinesP(\n",
    "        img, rho, theta, threshold, np.array([]),\n",
    "        minLineLength = min_line_len, maxLineGap = max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype = np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img, lines\n",
    "\n",
    "\n",
    "def separate_left_right_lines(lines):\n",
    "    \"\"\"Separate left and right lines depending on the slope.\"\"\"\n",
    "    left_lines = []\n",
    "    right_lines = []\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            for x1, y1, x2, y2 in line:\n",
    "                if y1 > y2: # Negative slope = left lane.\n",
    "                    left_lines.append([x1, y1, x2, y2])\n",
    "                elif y1 < y2: # Positive slope = right lane.\n",
    "                    right_lines.append([x1, y1, x2, y2])\n",
    "    return left_lines, right_lines\n",
    "\n",
    "\n",
    "def cal_avg(values):\n",
    "    \"\"\"Calculate average value.\"\"\"\n",
    "    if not (type(values) == 'NoneType'):\n",
    "        if len(values) > 0:\n",
    "            n = len(values)\n",
    "        else:\n",
    "            n = 1\n",
    "        return sum(values) / n\n",
    "\n",
    "\n",
    "def extrapolate_lines(lines, upper_border, lower_border):\n",
    "    \"\"\"Extrapolate lines keeping in mind the lower and upper border intersections.\"\"\"\n",
    "    slopes = []\n",
    "    consts = []\n",
    "    \n",
    "    if (lines is not None) and (len(lines) != 0):\n",
    "        for x1, y1, x2, y2 in lines:\n",
    "            slope = (y1-y2) / (x1-x2)\n",
    "            slopes.append(slope)\n",
    "            c = y1 - slope * x1\n",
    "            consts.append(c)\n",
    "        avg_slope = cal_avg(slopes)\n",
    "        avg_consts = cal_avg(consts)\n",
    "\n",
    "        # Calculate average intersection at lower_border.\n",
    "        x_lane_lower_point = int((lower_border - avg_consts) / avg_slope)\n",
    "\n",
    "        # Calculate average intersection at upper_border.\n",
    "        x_lane_upper_point = int((upper_border - avg_consts) / avg_slope)\n",
    "\n",
    "        return [x_lane_lower_point, lower_border, x_lane_upper_point, upper_border]\n",
    "\n",
    "\n",
    "def extrapolated_lane_image(img, lines, roi_upper_border, roi_lower_border):\n",
    "    \"\"\"Main function called to get the final lane lines.\"\"\"\n",
    "    lanes_img = np.zeros((img.shape[0], img.shape[1], 3), dtype = np.uint8)\n",
    "    # Extract each lane.\n",
    "    lines_left, lines_right = separate_left_right_lines(lines)\n",
    "    lane_left = extrapolate_lines(lines_left, roi_upper_border, roi_lower_border)\n",
    "    lane_right = extrapolate_lines(lines_right, roi_upper_border, roi_lower_border)\n",
    "    if lane_left is not None and lane_right is not None:\n",
    "        draw_con(lanes_img, [[lane_left], [lane_right]])\n",
    "    return lanes_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mtRMcnr_yCOL"
   },
   "source": [
    "### <font style='color:rgb(50,120,230)'> 1.2 New function for drawing area between the lanes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-qSJWiNLyCOM"
   },
   "outputs": [],
   "source": [
    "def draw_con(img, lines):\n",
    "    \"\"\"Fill in lane area.\"\"\"\n",
    "    points = []\n",
    "    for x1,y1,x2,y2 in lines[0]:\n",
    "        points.append([x1,y1])\n",
    "        points.append([x2,y2])\n",
    "    for x1,y1,x2,y2 in lines[1]:\n",
    "        points.append([x2,y2])\n",
    "        points.append([x1,y1])\n",
    "\n",
    "    points = np.array([points], dtype = 'int32')        \n",
    "    cv2.fillPoly(img, points, (0,255,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GVo6SVmvyCOM"
   },
   "source": [
    "# 2. Create the Main Process Loop Function\n",
    "\n",
    "This will be called over each frame of our dashcam video feed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pdclrddPyCOM"
   },
   "outputs": [],
   "source": [
    "def process_image(image):  \n",
    "    # Convert to grayscale.\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Intensity selection.\n",
    "    gray_select = cv2.inRange(gray, 150, 255)\n",
    "    \n",
    "    # Region masking: Select vertices according to the input image.\n",
    "    roi_vertices = np.array([[[100, 540], [900, 540], [525, 330], [440, 330]]])\n",
    "    gray_select_roi = region_of_interest(gray_select, roi_vertices)\n",
    "    \n",
    "    # Canny Edge Detection.\n",
    "    low_threshold = 50\n",
    "    high_threshold = 100\n",
    "    img_canny = cv2.Canny(gray_select_roi, low_threshold, high_threshold)\n",
    "    \n",
    "    # Remove noise using Gaussian blur.\n",
    "    kernel_size = 5\n",
    "    canny_blur = cv2.GaussianBlur(img_canny, (kernel_size, kernel_size), 0)\n",
    "    \n",
    "    # Hough transform parameters set according to the input image.\n",
    "    rho = 1\n",
    "    theta = np.pi/180\n",
    "    threshold = 100\n",
    "    min_line_len = 50\n",
    "    max_line_gap = 300\n",
    "    hough, lines = hough_lines(canny_blur, rho, theta, threshold, min_line_len, max_line_gap)\n",
    "    \n",
    "    # Extrapolate lanes.\n",
    "    roi_upper_border = 330\n",
    "    roi_lower_border = 540\n",
    "    lane_img = extrapolated_lane_image(image, lines, roi_upper_border, roi_lower_border)\n",
    "    \n",
    "    # Combined using weighted image.\n",
    "    image_result = cv2.addWeighted(image, 1, lane_img, 0.4, 0.0)\n",
    "    return image_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GnuQO_EMyCON"
   },
   "source": [
    "# 3. Setup video capture\n",
    "\n",
    "<hr style=\"border:none; height: 4px; background-color:#D3D3D3\" />\n",
    "\n",
    "### <font color=\"green\">OpenCV Documentation</font>\n",
    "\n",
    "[**`VideoCapture()`**](https://docs.opencv.org/4.5.2/d8/dfe/classcv_1_1VideoCapture.html#ac4107fb146a762454a8a87715d9b7c96) \n",
    "\n",
    "[**`VideoWriter()`**](https://docs.opencv.org/4.5.2/dd/d9e/classcv_1_1VideoWriter.html#ad59c61d8881ba2b2da22cff5487465b5) \n",
    "\n",
    "[**`write()`**](https://docs.opencv.org/4.5.2/dd/d9e/classcv_1_1VideoWriter.html#a30ebbc09c122332f62bd706b43f02a98)\n",
    "\n",
    "[**`release()`**](https://docs.opencv.org/4.5.2/dd/d9e/classcv_1_1VideoWriter.html#a667f737e56d5ba6b0533c6c7bf941140) <br>\n",
    "\n",
    "<hr style=\"border:none; height: 4px; background-color:#D3D3D3\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "16jjA57XyCON"
   },
   "outputs": [],
   "source": [
    "# Initialize our video capture.\n",
    "video_cap = cv2.VideoCapture('lane1-straight.mp4')\n",
    "if not video_cap.isOpened(): \n",
    "  print(\"Error opening video stream or file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HvrzP1z9yCON"
   },
   "outputs": [],
   "source": [
    "# Retrieve video frame properties.\n",
    "frame_w   = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_h   = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_fps = int(video_cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Select fourcc encoding for the mp4 file.\n",
    "# Having issues? You could also try: *'mp4v' or *'avc1'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "# Specify the video output filenames.\n",
    "file_out = 'lane1-straight-output.mp4'\n",
    "\n",
    "# Create the video writer objects.\n",
    "vid_out = cv2.VideoWriter(file_out, fourcc, frame_fps, (frame_w,frame_h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WEzUex8vyCON",
    "outputId": "77fb5d16-903d-4b2e-b59e-af7f2ef56540"
   },
   "outputs": [],
   "source": [
    "# Run the main loop over every frame of the input video.\n",
    "print(\"Begin processing video... Wait until 'finished' message!\")\n",
    "while True:\n",
    "    ret, frame = video_cap.read()\n",
    "    if frame is None:\n",
    "        print(\"Finished processing video\")\n",
    "        break\n",
    "    result = process_image(frame)\n",
    "    vid_out.write(result)\n",
    "\n",
    "# Close the video writer stream.\n",
    "vid_out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "40Dd9TQKyCOO"
   },
   "outputs": [],
   "source": [
    "# Display the saved video file.\n",
    "from moviepy.editor import *\n",
    "clip = VideoFileClip(file_out)\n",
    "clip.ipython_display(width = 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hvHq3DoyCOO"
   },
   "source": [
    "\n",
    "Now you are able to detect straight lane lines. It is worth understanding some of the hard coded assumption this pipeline took around area of interest. You can consider possible extensions, such as detecting the horizon level and adjusting the size of the trapezoid region of interest accordingly.\n",
    "\n",
    "Furthermore, in real world scenario, the roads are not always straight. Additionally, sometimes the visibility might be low. You can go a step further and see how this pipeline performs over some extreme situations."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "09_02_Lane_Detection_Straight_Lane_Video.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "ebc319c8538a0dff9f27bfc0a3142b806f989e03741f3022156954c3f29d1992"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
